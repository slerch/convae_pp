# Convolutional autoencoders for spatially-informed ensemble post-processing

This repository provides code accompanying the paper

> Lerch, S. and Polsterer, K.L. (2022).
> Convolutional autoencoders for spatially-informed ensemble post-processing.
> International Conference on Learning Represenatations (ICLR) 2022, AI for Earth and Space Science Workshop

... overview of contribution, model schematic

## Data

The data needed to reproduce the results consists of two input and one observation dataset. The station-based NWP predictors and the correspodinding observations are available in the follwoing: 

> Rasp, Stephan (2021): PPNN full data (feather format). figshare. Dataset. https://doi.org/10.6084/m9.figshare.13516301.v1 

The spatial input fields are too large to share in a straightforward way, they can be obtained from the TIGGE dataset (https://confluence.ecmwf.int/display/TIGGE), following the instructions provided in https://github.com/slerch/ppnn/tree/master/data_retrieval.

## Convolutional autoencoder models

...

## Neural network-based post-processing models and incorporating spatial inputs

...
